\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic,array}
\usepackage[ruled,noline,linesnumbered,noend]{algorithm2e}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}

% algorithm styling
\SetInd{0.5em}{0.2em}       % reduce indent
\newcommand\mycommentfont[1]{\footnotesize\sffamily{#1}}
\SetCommentSty{mycommentfont}

% fun with colors
\RequirePackage{color}
\usepackage{colortbl}
\definecolor{RED}{rgb}{1,0,0}
\definecolor{BLUE}{rgb}{0,0,1}
\definecolor{GREEN}{rgb}{0,1,0}
\definecolor{color1}{rgb}{0.913, 0.776, 0.686}
\definecolor{color2}{rgb}{0.913, 0.867, 0.686}
\definecolor{ltgray}{rgb}{0.85, 0.85, 0.85}

% notes, remarks, todo
\newcommand{\Remark}[1]{{\color{RED}\sf Remark: {#1}}}
\newcommand{\tp}[1]{{\color{RED}\sf TP: {#1}}}
\newcommand{\dm}[1]{{\color{BLUE}\sf DM: {#1}}}
\newcommand{\Fix}[1]            {\textcolor{red}{\small\sf [#1]}}
\newcommand{\kw}[1]             {{\tt #1}\xspace}
\newcommand{\todo}[1]{
      \addcontentsline{tdo}{todo}{\protect{#1}}
      \marginpar{\colorbox{white!90!black}{\textcolor{red}{
      \parbox{2.1cm}{\scriptsize\bf\raggedright #1}
      }}}
}

\usepackage{etoolbox}

\usepackage{wrapfig}
\usepackage{pgfplots}
\usepackage{tikz}
\usetikzlibrary{decorations.shapes}
%\pgfplotsset{width=10cm,compat=1.9}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{calc}

\tikzset{
	myarrow/.style={-{Triangle[length=3mm,width=1mm]}}
}

\usepackage[norndcorners,customcolors,nofill]{hf-tikz}
\hfsetbordercolor{black!50}


\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Parallel Domain Decomposition Techniques Applied to Multi-Variate Functional Approximation of Discrete Data\\
%{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and should not be used}
%\thanks{Identify applicable funding agency here. If none, delete this.}
\thanks{Early Career Research Program, Department of Energy, US}
}

\author{\IEEEauthorblockN{1\textsuperscript{st} Vijay S. Mahadevan}
\IEEEauthorblockA{\textit{Mathematics and Computational Science Division} \\
\textit{Argonne National Laboratory}\\
Lemont, IL, 60439, USA \\
mahadevan@anl.gov}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Thomas Peterka}
\IEEEauthorblockA{\textit{Mathematics and Computational Science Division} \\
\textit{Argonne National Laboratory}\\
Lemont, IL, 60439, USA \\
tpeterka@mcs.anl.gov}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Iulian Grindeanu}
\IEEEauthorblockA{\textit{Mathematics and Computational Science Division} \\
\textit{Argonne National Laboratory}\\
Lemont, IL, 60439, USA \\
iulian@anl.gov}
\and
\IEEEauthorblockN{4\textsuperscript{th} Youssef Nashed}
\IEEEauthorblockA{\textit{Stats Perform}\\
Chicago, IL, 60601, USA \\
youssef.nashed@statsperform.com}
}

\maketitle

\begin{abstract}
Compactly expressing large-scale datasets through multivariate functional approximations (MFA) can be critically important for analysis and visualization to drive scientific discovery. This paper presents a data and domain partitioning approach to scalably compute a MFA representation, by reducing the total work per task in combination with a nonlinear Schwarz-type, inner-outer iterative scheme for converging the interface data. For the underlying MFA, we utilize a tensorial expansion of non-uniform B-spline (NURBS) basis to adaptively reduce the functional approximation error in the input data. While previous work on adaptive NURBS-based MFA has been proven successful, the computational complexity for encoding large datasets on a single process can be prohibitive. We demonstrate effectiveness of the presented approach with an overlapping Jacobi additive Schwarz method (JASM) based domain decomposition solver, with a nonlinear accelerator such as L-BFGS or Krylov (CGS, L-GMRes) to minimize the subdomain error residuals obtained from decoding the MFA, and more specifically to resolve the discontinuities at boundaries. The analysis of the presented scheme for some analytical and real scientific datasets in 1-D and 2-D are also presented. Additionally, scalability studies are also shown for some real-world 2-d datasets to evaluate the parallel speedup of the algorithm on large clusters.
\end{abstract}

\begin{IEEEkeywords}
functional approximation, domain decomposition, scalable methods
\end{IEEEkeywords}

\section{Introduction}

Large scale discrete data analysis from various scientific computational simulations often require high-order continuous functional representations that have to be evaluated anywhere in the domain. Such expansions described as Multivariate Functional Approximations (MFA) in arbitrary dimensions \cite{nurbs-book} allow the original discrete data to be compressed, and expressed in a compact closed form in addition to supporting higher-order derivative queries. One particular option is to use NURBS bases for the MFA encoding of scattered data \cite{peterka-mfa}. Due to the potentially large datasets that need to be encoded into a MFA, the need for computationally efficient algorithms (in both time and memory) to partition the work into subtasks is critically important. 

In the current paper, we utilize domain decomposition (DD) techniques \cite{smith-ddm} with data partitioning strategies to produce scalable algorithms to adaptively compute the MFA to reproduce a given dataset within user-specified tolerances. In such partitions, it is imperative to ensure that the continuity of the data across subdomain interfaces are maintained and is consistent with the degree of the underlying bases used in the MFA. 
We present an iterative DD scheme with an outer Schwarz-type iterative scheme in order to ensure that continuity is recovered, and the overall error stays bounded when number of subdomains are increased (subdomain size decreases).

%{\color{red}THIS IS A DRAFT}

%\begin{itemize}
%	\item Talk about MFA and how it can be used to approximation discrete solution data. Reference previous work.
%	\item Provide motivations on why this is necessary especially for large datasets
%	\item Literature survey of other work for parallel interpolation and compression of data
%	\item What are the other approaches to address this issue; pros and cons
%\end{itemize}

The paper is organized as follows. Section 2 summarizes the related work in using variations of the Schwarz scheme for scalably interpolating data, and using constraints for recovering continuity along discontinuous patches. Section 3 provides details about the constrained optimization problem to resolve subdomain boundary discontinuities, along with the outer-inner DD based solver setup to compute the continuous MFA. Next the application of the DD solver for 1-D/2-D analytical problems are provided to verify error convergence, and scalability of the hierarchical scheme with decreasing subdomain size under overlap specifications. Finally, the parallel scalability of the scheme is presented for some real-world cases to adaptively compute the MFA within user-specified tolerances.


\section{Related Work}

DD techniques for parallel interpolation of scattered data has been explored previously with Radial Basis Functions (RBF) \cite{mai-approx-rbf}, yielding good scalability to create a MFA that closely replicates underlying profile. Overlapping variants of multiplicative and additive Schwarz iterative techniques for RBF \cite{ddm-rbf} have been proven successful to tackle large problems. Additionally, use of restricted Additive-Schwarz preconditioners with Krylov iterative solvers have been shown to be scalable \cite{yokota-rasm-rbf} for such problems as well. However, using NURBS-basis to compute MFA in parallel, while maintaining higher-order continuity across subdomains has not been explored previously in this context. To overcome the issues with discontinuities along NURBS patches, \cite{zhang-nurbs-continuity} have proposed to use a gradient projection scheme to constrain the value ($G_0$), the gradient ($G_1$) and the hessian ($G_2$) at a small number of test points for optimal shape recovery. 



While it is also possible to create such a constrained recovery during the actual post-processing stage i.e., decoding of the MFA through blending techniques \cite{grindeanu-blending}, the underlying MFA representation would remain discontinuous, and would become more so with increasing number of subdomains. In contrast, we propose an extension to the constrained solvers used by \cite{zhang-nurbs-continuity, xu-jahn-discrete-adjoint} by utilizing a recursive DD-based parallel outer-inner iterative scheme to resolve continuity prescriptions as required by the user. The outer iteration utilizes a flavor of the restricted Additive-Schwarz method (RASM) \cite{gander-rasm}, with an efficient, inner subdomain solver using L-BFGS as used in \cite{zheng-bo-bspline-bfgs}, or Krylov-type schemes (CGS, L-GMRes) to minimize the decoded residual within acceptable error tolerances. This DD solver has low memory requirements that scales with growing subdomains, and only imposes nearest neighbor communication of the interface data once per outer iteration. 

{\color{red}
	
	** PetIGA and other parallel NURBS algos/software
	
	** talk about T-splines and how it can simplify the constraint specification; 
	
	** also mention looking at the problem in a lagrange multiplier setting
	
}

\section{Approach}

Domain decomposition techniques in general rely on the idea of splitting a larger domain into smaller subdomains, which results in coupled Degrees-of-Freedom (DoF) at their common interface. Typical applications in Boundary-Value problems (BVP) \cite{smith-ddm, lions-asm} have been employed successfully for efficiently computing the solution to large Partial Differential Equations (PDEs) with DD in a scalable fashion. In the current work, we utilize a data decomposition approach, with possibility of overlapping or shared layers such that higher-order continuity across domain boundaries are preserved in order to generate consistent and accurate MFA representations in parallel. Similar to overlapping Schwarz solvers for PDE applications, the amount of overlap in the data for MFA directly affects the convergence speed and scalability of the overall algorithm. And the overall accuracy of the parallel algorithm cannot be worse than the single subdomain case.

For illustration, consider a 1-D domain ($\Omega$) with two partitions as shown in Fig. \ref{fig:DD-subdomain-illiustration}, where $\Omega_1$ and $\Omega_2$ represent the subdomains that share an interface $d\Omega_{1,2}$. If the scheme is invoked with an overlap layer $\Delta$, the corresponding overlaps are also shown as $\Delta_1$ and $\Delta_2$.

\tikzset{decorate sep/.style 2 args=
	{decorate,decoration={shape backgrounds,shape=circle,shape size=#1,shape sep=#2}}}

\begin{figure}
\centering
\begin{tikzpicture}
\begin{scope}[very thick]
\begin{axis}[cycle list name=exotic, legend style={draw=none}, axis lines=none, xtick=\empty, ytick=\empty, xmin=0, xmax=100, ymin=0.8, ymax=1.2]
%\begin{axis}[legend style={draw=none},xmin=-5, xmax=105, ymin=0.8, ymax=1.2]

\addplot[domain=0:50, samples=6, color=blue, mark=halfcircle] {1.0};

\addplot[domain=50:100, samples=6, color=red, mark=halfcircle] {1.0};
%\addplot[color=blue] coordinates {0,0.5} ;
%\addplot +[mark=none] coordinates {(0.5,1.25) (0.5,0.75)};
%\addplot[domain=0.5:1, samples=6, color=black] {1};
%\addplot coordinates {(0,1) (0.1,1) (0.2,1) (0.3,1) (0.4,1) (0.5,1) (0.6,1) (0.7,1) (0.8,1) (0.9,1) (1,1)};
%\draw[decorate sep={1mm}{2mm},fill] (0,0) -- (100,0);
%\draw[myarrow] (0,0) -- (1,5.5);

\draw [decorate,decoration={brace,mirror,amplitude=20pt},color=blue,xshift=0pt,yshift=70pt]
(0,0.9) -- (50,0.9) node [black,midway,yshift=-1cm] 
{\footnotesize $\Omega_1$};

\draw [decorate,decoration={brace,mirror,amplitude=5pt},color=blue,xshift=0pt,yshift=70pt]
(50,0.9) -- (60,0.9) node [black,midway,yshift=-5mm] 
{\footnotesize $\Delta_1$};

\draw [decorate,decoration={brace,amplitude=20pt},color=red,xshift=0pt,yshift=90pt]
(50,1.1) -- (100,1.1) node [black,midway,yshift=1cm] 
{\footnotesize $\Omega_2$};

\draw [decorate,decoration={brace,amplitude=5pt},color=red,xshift=0pt,yshift=90pt]
(40,2.1) -- (50,2.1) node [black,midway,yshift=5mm] 
{\footnotesize $\Delta_2$};

\addplot [dashed, black, thick] coordinates {(50,1.15)  (50,0.85)} node[above left] {\footnotesize $\Omega_{1,2}$ } ;

\end{axis}
\end{scope}
\end{tikzpicture}
\caption{1-D Parallel Partitioned Domain}
\label{fig:DD-subdomain-illiustration}
\end{figure}


It is imperative to note that the only exchange of data between subdomains is performed through nearest neighbor communication that has bounded complexity and costs. The volume of messages exchanged however depends on several factors.
\begin{enumerate}
	\item \textbf{Continuity}: The degree of continuity determines the stencil needed to enforce the constraints on either side of the interface
	\item \textbf{Overlap}: The number of overlap layers in the data determines the control point data coupling to be communicated between neighboring domains
\end{enumerate}


%\begin{itemize}
%	\item What are we proposing and why this can be a stable technique to recover high-order continuity in parallel ?
%	\item Give context about DD methods and how ASM in this context makes sense 
%	\item Refer to \cite{smith-ddm} and \cite{ddm-rbf} as well and write out the equations with \cite{nurbs-book} help
%\end{itemize}

\subsection{Solver Methodology}

A pth degree NURBS curve \cite{nurbs-book} is defined using the Cox-deBoor functions as

\begin{eqnarray}
C(u) &=& \sum_{i=0}^{n} R_{i,p}(u) P_i, \forall u \in \Omega \\
R_{i,p}(u) &=& \frac{N_{i,p}(u) w_i}{\sum_{i=0}^{n} N_{i,p}(u) w_i}
\label{eq:nurbs-basis}
\end{eqnarray}

where $R_{i,p}(u)$ are the piecewise rational functions with $P_i$ control points, $w_i$ weights and p-th degree B-spline basis $N_{i,p}(u)$ defined on a knot-vector $U$. Exact high-order derivatives of these NURBS basis defined in Equation. \ref{eq:nurbs-basis} can also be evaluated without any approximation errors at the control point locations.

Given a set of input points that need to be encoded $Q$, the linear Least-Squares (LLS) fitting algorithm can be applied to compute the control point data. This results in a normal form of linear equations to be solved as follows.

\begin{equation}
(N^T R) P = N^T Q
\end{equation}

The iterative scheme used in the current work utilizes the unconstrained LLS solve as the first initial guess $P_{LS}$ to compute the optimal solution in each subdomain. Once $P_{LS}$ is available for the individual subdomains, the global nonlinear problem with subdomain boundary constraints can be written out as

\begin{equation}
A(X) X = F, \quad X = \left[P1 ; P2 \right]
\label{eq:global-system}
\end{equation}

where
\begin{equation}
A(X) =
\left[
\begin{array}{c|c}
A_{1,1}(P_1) & A_{1,2}(P_1,P_2) \\
\hline
A_{2,1}(P_1,P_2) & A_{2,2}(P_1)
\end{array}
\right]
\label{eq:coupled-operator}
\end{equation}

and

\begin{equation}
F = \left[
\begin{array}{c}
N_1^T Q_{1} \\
N_2^T Q_{2}
\end{array}
\right]
\end{equation}

The diagonal operators $A_{1,1}$ and $A_{2,2}$ correspond to the linear operator that minimizes the local subdomain residuals while the off-diagonal blocks $A_{1,2}$ and $A_{2,1}$ represent the coupling terms between the subdomains at $\Omega_{1,2}$. This coupling term contains the constraints on the shared control points, its derivatives and the weights along subdomain boundaries, satisfying which will enforce solution continuity in the global MFA representation. 

The coupling blocks can also be reformulated to introduce Lagrange multipliers to explicitly couple the control points, derivatives and weights across a subdomain interface such that continuity is preserved in a weak sense \cite{nurbs-book}. In the current paper, we instead use the Schur complement of Equation \ref{eq:coupled-operator} to eliminate the coupling terms by evaluating it at the lagged iterate values, in order to impose constraints in each subdomain independently. Hence, the coupled data $P_2, W_2$ and $P_1, W_1$ for subdomains $\Omega_1$ and $\Omega_2$ respectively are exchanged simultaneously before the local domain solves are computed. Since the exchanged constraint data is lagged, it can slightly slow down iteration convergence in comparison to the more expensive multiplicative Schwarz variants \cite{smith-ddm}. The key advantage of this block-Jacobi type operator leading to the restricted additive Schwarz method (RASM) is that it only requires nearest neighbor exchange of data, that keeps communication costs bounded as number of subdomains increase \cite{gander-rasm}. 

Note that once the interface data terms are obtained, a Schur complement of Equation \ref{eq:coupled-operator} can be computed to eliminate the coupling terms and to impose a constraint in each subdomain independently. This leads to an augmented subdomain solution as shown in Equation \ref{eq:augmented-solution} that includes the control point, and optionally the derivative and weights at the interface obtained from the adjacent subdomain. 

\begin{equation}
\tikzset{left offset=-0.02,right offset=0.02,disable rounded corners=true}
%\begin{array}{@{} *{2}{ c @{} >{{}}c<{{}} @{} } c @{}}
%16\cdot \tikzmarkin{A}I_1  & + & 11\cdot \tikzmarkin{B}I_2  & = & \tikzmarkin{C}13\\[1ex]
%11\cdot I_1\tikzmarkend{A} & + & 16\cdot I_2\tikzmarkend{B} & = & 17\tikzmarkend{C}
%\end{array}
P_1^{'} =
\left[
\begin{array}{c}
\tikzmarkin{A}(1,-0.1)(0,0.3) P_1(1)   \\
P_1 (2) \\
\vdots   \\
\tikzmarkend{A} P_1 (m) \\
\tikzmarkin{B}(0.6,-0.1)(0,0.3) P_2(1) \\
0 \\
\vdots \\
\tikzmarkend{B} 0
\end{array}
\right],
P_2^{'} =
\left[
\begin{array}{c}
\tikzmarkin{C}(1,-0.1)(0,0.3) P_2(1)   \\
P_2 (2) \\
\vdots   \\
\tikzmarkend{C} P_2 (n) \\
\tikzmarkin{D}(0.6,-0.1)(0.0,0.3) P_1(1) \\
0 \\
\vdots \\
\tikzmarkend{D} 0
\end{array}
\right]
\label{eq:augmented-solution}
\end{equation}
\begin{tikzpicture}[remember picture,overlay]
% adjust the shift from "col" to move the position of the annotation
\coordinate (A-aa) at ($(A)+(-0.5,-1.0)$);
\node[align=left,left] at (A-aa) {\small{$\Omega_1$}};
\path[-stealth,blue,draw] (A-aa) -| ($(A)+(0.2,-1.2)$);


% adjust the shift from "col" to move the position of the annotation
\coordinate (B-aa) at ($(B)+(-0.5,-1.0)$);
\node[align=left,left] at (B-aa) {\small{$\Delta_1$}};
\path[-stealth,blue,draw] (B-aa) -| ($(B)+(0.2,-1.2)$);


% adjust the shift from "col" to move the position of the annotation
\coordinate (C-aa) at ($(C)+(1.4,-1.0)$);
\node[align=right,right] at (C-aa) {\small{$\Omega_2$}};
\path[-stealth,red,draw] (C-aa) -| ($(C)+(0.75,-1.2)$);

% adjust the shift from "col" to move the position of the annotation
\coordinate (D-aa) at ($(D)+(1.4,-1.0)$);
\node[align=right,right] at (D-aa) {\small{$\Delta_2$}};
\path[-stealth,red,draw] (D-aa) -| ($(D)+(0.75,-1.2)$);

\end{tikzpicture}

where $m, n$ are the number of control points in $\Omega_1$ and $\Omega_2$ respectively.

At convergence, the interface data at $\Omega_{1,2}$ will satisfy the continuity prescriptions specified by the user ($G_0$, $G_1$, $G_2$). The illustration and description can be generalized and extended to arbitrary dimensions and will be used as the basis for the local subdomain solvers introduced further in the following subsections.

\subsection{Constrained Least-Squares Solver}

Iterative constrained LSQ solver from \cite{nurbs-book}


\subsection{Constrained Nonlinear Solver}

Use L-BFGS or Krylov iterative schemes to converge the local subdomain residuals \cite{zhang-nurbs-continuity} \cite{zheng-bo-bspline-bfgs}

Talk about how control point constraints are imposed in a penalized form 

\subsection{Constrained Nonlinear Solver on Decoded Data}

Instead of imposing the constraints in the control point space, we utilize the expansion of the MFA in input point space directly to minimize the decoded residual $R P - Q$. There are some advantages to this approach compared to imposing the interface constraints in the control point space.

\begin{enumerate}
	\item Both subdomain residuals and boundary constraints are in the decoded space
	\item No need for a penalty term since the nonlinear solver minimizes the entire residual space
\end{enumerate}

Explain the iterative scheme in terms of the underlying equations and how the boundary terms are resolved through a global ASM method. First start with 1-d and talk about extensions in the scheme to allow arbitrary dimensional solver framework.


Note that in a Jacobi-Schwarz outer iterative scheme, nearest neighbor exchanges can be performed compactly per dimension and direction, thereby minimizing communication costs and eliminating global collectives.


\subsection{Implementation}

We implemented the code in this article in Python using pyDIY. DIY~\cite{morozov16} is a programming model and runtime
for block-parallel analytics on distributed-memory machines, built on MPI-3~\cite{dongarra13}.  Rather than programming
for process parallelism directly in MPI, the programming model in DIY is based on block parallelism: data are decomposed
into subdomains called blocks; blocks are assigned to processing elements (processes or threads); computation is
described over these blocks, and communication between blocks is defined by reusable patterns. The same DIY program
consisting of a block-parallel decomposition can be run on different numbers of MPI processes: it is the job of the DIY
runtime to map between blocks and processes. A recent development in DIY is a development branch of pyDIY~\cite{pydiy},
a set of Python bindings for DIY, using pybind11~\cite{jakob17} and mpi4py~\cite{dalcin11}.

The overall approach is sketched in Algorithm~\ref{alg:pseudocode}. \Remark{Vijay: finish the pseudocode and expand the
discussion of it below.} We begin by decomposing the domain into a set of regular blocks aligned with the principal axes
of the global domain. We then begin iterating over the blocks in a 2-level nested loop: the outer loop is the ASM
approach described above, while the inner loop is a nonlinear optimization (BFGS or Krylov) to solve for the control
points of the MFA model in each block. At the bottom of each ASM iteration, we exchange the constraints
among neighboring blocks in a regular nearest-neighbor communication pattern, and we also perform a global
collective communication to determine whether the solution has converged to the desired error tolerance.

\Remark{Algorithm~\ref{alg:pseudocode} is just a skeleton. Details need to be filled in. Termination conditions, local
(inner loop) iterative scheme, types of constraints (control points or decoded points), etc.}

\begin{algorithm}
    \DontPrintSemicolon
    decompose domain into blocks\;
    \tcp*[h]{Outer ASM loop}\;
    \While{not globally done}
    {
        constraints $\leftarrow$ dequeue incoming constraints\;
        \tcp*[h]{Inner BFGS or Krylov optimization loop}\;
        \While{error decreasing and $iterate < max\_iterations$}
        {
            solve local MFA\;
            enqueue constraints to neighbor blocks\;
        }
        exchange constraints with neighbor blocks\;
        collect global error\;
    }
    \caption{\Remark{Caption TBD}}
    \label{alg:pseudocode}
\end{algorithm}

{\color{red}
DIY exclusively manages the data decomposition, including specifications to share an interface $\Omega_{1,2}$ and ghost layers that represent overlaps $\Delta$.

** talk about nearest neighbor communication is done once per outer iteration; 
** DIY send/recv workflow fits naturally with exchanging data once per iteration. Jacobi-Schwarz is a natural algorithmic fit to create performant MFA encoders in parallel.
}


\section{Results}

Explain about the common problem datasets that we are going to be using and why they have been chosen.

Please note sections \ref{AA}--\ref{SCM} below for more information on 
proofreading, spelling and grammar.

\subsection{1-d Results}\label{AA}

Problem setups
\begin{itemize}
  \item Sine
  \item Sinc
  \item S3D
  \item Dow-Jones historical daily data
\end{itemize}

\begin{itemize}
	\item Use the first two problems to measure convergence in parallel as number of domains increase
	\item Talk about adaptivity and resolution of data even for highly varying problem data.
\end{itemize}

\subsection{2-d Results}

Problem setups
\begin{itemize}
	\item Sinc
	\item Nek5000
	\item S3D
	\item CESM data
\end{itemize}


\begin{itemize}
	\item Adaptive algorithms to resolve data and provide compression
	\item DD scheme with ASM in combination with adaptivity.
	\item Discuss about complications and potential ways to enforce continuity. (a) Use decoded data, (b) Use control point space across interface
\end{itemize}

\subsection{Parallel Scalability}\label{SCM}

Showcase some scalability results on Bebop for the 2-d problem; Take S3D and CESM datasets, along with artificial sinc combination functions.

How does the nearest neighbor communication stay bounded ?

%\paragraph{Positioning Figures and Tables} Place figures and tables at the top and 
%``Fig.~\ref{fig}'', even at the beginning of a sentence.

%\begin{table}[htbp]
%\caption{Table Type Styles}
%\begin{center}
%\begin{tabular}{|c|c|c|c|}
%\hline
%\textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
%\cline{2-4} 
%\textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
%\hline
%copy& More table copy$^{\mathrm{a}}$& &  \\
%\hline
%\multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
%\end{tabular}
%\label{tab1}
%\end{center}
%\end{table}

%\begin{figure}[htbp]
%\centerline{\includegraphics{fig1.png}}
%\caption{Example of a figure caption.}
%\label{fig}
%\end{figure}

\section{Conclusion}

We have presented a scalable DD approach to tackle the issue of discontinuous MFA representations when performing the computations in parallel. Through the user of Jacobi-Schwarz iterative schemes, combined with L-BFGS or Krylov solvers for local subdomain solves, the hierarchic iterative technique was proven to be robust in converging to the compressed functional representation of the given data, without sacrificing the approximation accuracy. Combining NURBS-based adaptivity with a-posteriori error measures, and ensuring higher-order continuity across block boundaries, a scalable infrastructure has been presented. The PyDIY based Python implementations for 1-D and 2-D problems have been shown here to resolve complex solution profiles and gradient variations, even under decreasing subdomain sizes. The use of overlap layers can definitely improve the overall MFA accuracy and convergence speed of the JS algorithm as shown for the 1-D analytical problems, but at a slightly higher cost per iteration. The strong scalability of the algorithm was also explored for a reasonably large 2-D climate dataset {\color{red} talk about 2-d scalability when we have the results}

A more natural way to ensure continuity across NURBS patches would be use T-splines which is specifically designed for merging higher-dimensional surfaces with non-matching knot locations. The implementation of T-splines for adaptivity in the context of MFA is currently being explored, and the presented ASM based solver approach can still be used to impose constraints across subdomain patch boundaries. 

{\color{red} 
	should we talk about implementation of the code in C++ as future work?
	it would also be interesting to use multilevel techniques to create a hierarchical MFA representation and use ASM to accelerate finer solves using coarser control point data. Need to explore this idea further but can propose it here as future exploration topic
}

%\begin{itemize}
%	\item What did we implement to enhance speedup of the MFA framework and did we preserve accuracy of the underlying method ?
%	\item Did we speedup the actual computation by performing DD with ASM global iterations for some of the problem data ?
%	\item Does the method scale as a function of domains and problem size ? 
%	\item What advantages does it provide for fix-up schemes that can be used in a post-processing step (ref Iulian's blending idea) ?
%	\item Future extensions to T-splines and local adaptivity and potential complications involved
%\end{itemize}

\section*{Acknowledgment}

This work is supported by Advanced Scientific Computing Research, Office of Science, U.S. Department of Energy, under
Contract DE-AC02-06CH11357, program manager Laura Biven. We gratefully acknowledge the computing resources provided on
Bebop, a high-performance computing cluster operated by the Laboratory Computing Resource Center (LCRC) at Argonne
National Laboratory.

\bibliographystyle{IEEEtran}
\bibliography{asm-mfa}

%\vspace{12pt}
%\color{red}
%IEEE conference templates contain guidance text for composing and formatting conference papers. Please ensure that all template text is removed from your conference paper prior to submission to the conference. Failure to remove the template text from your paper may result in your paper not being published.

\end{document}
